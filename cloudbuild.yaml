# Cloud Build configuration for automatic deployment with optimized caching
#
# Key optimizations:
# 1. Kaniko for Docker layer caching (reuses cached layers across builds)
# 2. Parallel push operations
# 3. Combined deploy steps where possible
#
# To enable auto-deploy on merge to main, create a trigger in GCP Console:
#   1. Go to Cloud Build > Triggers
#   2. Click "Create Trigger"
#   3. Name: "deploy-on-main-merge"
#   4. Event: "Push to a branch"
#   5. Source: Select your repository
#   6. Branch: ^main$ (regex)
#   7. Configuration: Cloud Build configuration file (this file)
#   8. Click "Create"
#
# Or use gcloud CLI:
#   gcloud builds triggers create github \
#     --repo-name=crowdit-mcp-server \
#     --repo-owner=chrisgermon \
#     --branch-pattern="^main$" \
#     --build-config=cloudbuild.yaml \
#     --name="deploy-on-main-merge"

steps:
  # Build with Kaniko for layer caching
  # Kaniko caches layers in Artifact Registry, dramatically speeding up subsequent builds
  - name: 'gcr.io/kaniko-project/executor:latest'
    id: 'build'
    args:
      - '--dockerfile=Dockerfile'
      - '--context=dir://.'
      - '--destination=australia-southeast1-docker.pkg.dev/$PROJECT_ID/crowdit/crowdit-mcp-server:$BUILD_ID'
      - '--destination=australia-southeast1-docker.pkg.dev/$PROJECT_ID/crowdit/crowdit-mcp-server:latest'
      # Enable layer caching - cache stored in Artifact Registry
      - '--cache=true'
      - '--cache-ttl=168h'
      - '--cache-repo=australia-southeast1-docker.pkg.dev/$PROJECT_ID/crowdit/crowdit-mcp-server-cache'
      # Optimize for faster builds
      - '--snapshot-mode=redo'
      - '--use-new-run'
      # Build args for reproducibility
      - '--build-arg=BUILDKIT_INLINE_CACHE=1'

  # Deploy to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'deploy'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - 'crowdit-mcp-server'
      - '--image'
      - 'australia-southeast1-docker.pkg.dev/$PROJECT_ID/crowdit/crowdit-mcp-server:$BUILD_ID'
      - '--region'
      - 'australia-southeast1'
      - '--platform'
      - 'managed'
      - '--no-allow-unauthenticated'
      - '--port=8080'
      - '--memory=1Gi'
      - '--cpu=1'
      - '--timeout=300'
      - '--concurrency=80'
      - '--min-instances=0'
      - '--max-instances=3'
      - '--cpu-boost'
      - '--set-env-vars=BIGQUERY_PROJECT_ID=$PROJECT_ID,BIGQUERY_JOB_PROJECT_ID=$PROJECT_ID,BIGQUERY_DATA_PROJECT_ID=vision-radiology,CIPP_TENANT_ID=299ea2a8-99a3-426c-9836-8a5c6eafe007,CIPP_CLIENT_ID=728a6a60-ba98-472f-b06a-3fb726ad8270,CIPP_API_URL=https://cippq7gcl.azurewebsites.net,NINJAONE_REGION=oc'
      # Secrets are loaded dynamically from Secret Manager at runtime (not via --set-secrets)
      # This prevents deployment failures when secrets don't exist yet
      # Integrations without configured secrets will show as "Not configured" on status page
      # Increase startup timeout for large Python module loading
      - '--startup-cpu-boost'
    waitFor: ['build']

images:
  - 'australia-southeast1-docker.pkg.dev/$PROJECT_ID/crowdit/crowdit-mcp-server:$BUILD_ID'
  - 'australia-southeast1-docker.pkg.dev/$PROJECT_ID/crowdit/crowdit-mcp-server:latest'

options:
  logging: CLOUD_LOGGING_ONLY
  # Use higher-spec machine for faster builds
  machineType: 'E2_HIGHCPU_8'
